---
title: Automated Text Summarization using Spacy in NLP | by Aparna Mishra | Medium
date: 2022-12-04
src_link: https://www.notion.so/Automated-Text-Summarization-using-Spacy-in-NLP-by-Aparna-Mishra-Medium-9faabd534f7949a5bfb9e7fb84c67978
src_date: '2022-12-04 11:17:00'
gold_link: https://aparnamishra144.medium.com/automated-text-summarization-using-spacy-in-nlp-8750b1b6e404
gold_link_hash: 7148cd4e89795c9386f4a9d7546a49bd
tags:
- '#host_aparnamishra144_medium_com'
---

Automated Text Summarization using Spacy in NLP
===============================================

[![](https://miro.medium.com/v2/resize:fill:88:88/1*r7-YZYfd-NiwfgTtyk2WnQ.jpeg)](/?source=post_page-----8750b1b6e404--------------------------------)[Aparna Mishra](/?source=post_page-----8750b1b6e404--------------------------------)

·[Follow](https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F33e5adfd4a6d&operation=register&redirect=https%3A%2F%2Faparnamishra144.medium.com%2Fautomated-text-summarization-using-spacy-in-nlp-8750b1b6e404&user=Aparna+Mishra&userId=33e5adfd4a6d&source=post_page-33e5adfd4a6d----8750b1b6e404---------------------post_header-----------)

6 min read·Oct 3, 2021--

This article will be an explanation of how to perform **Automated Text Summarization** using [**SpaCy**](https://spacy.io/usage/models) library which is an alternative of [**NLTK**](https://www.nltk.org/)

**spaCy** is a library for advanced **Natural Language Processing** in Python and Cython. It’s built on the very latest research, and was designed from day one to be used in real products. It comes with [pretrained pipelines](https://spacy.io/models) and currently supports tokenization and training for 60+ languages. It features state-of-the-art speed and neural network models for tagging, parsing, named entity recognition, text classification and more, multi-task learning with pretrained transformers like BERT, as well as a production-ready [training system](https://spacy.io/usage/training) and easy model packaging, deployment and workflow management.

spaCy is commercial open-source software, released under the MIT license.

**Automated Text Summarization** makes it easy to read lengthy documents and create an accurate summary in short time, this can also create summaries which are less biased as compared to human summarized documents.

It is part of Natural Language Processing field , where machines can interpret , analyze and extract meaning from human language.

Let’s see how to perform this operation.

Step 1: Getting our document / text.
------------------------------------


```
text = '''Yoga develops inner awareness. It focuses your attention on your body's abilities at the present moment.It helps develop breath and strength of mind and body. It's not about physical appearance.Yoga studios typically don't have mirrors. This is so people can focus their awareness inward rather than how a pose — or the people around them — looks.Surveys have found that those who practiced yoga were more aware of their bodies than people who didn't practice yoga.They were also more satisfied with and less critical of their bodies. For these reasons, yoga has become an integral part in the treatment of eating disorders and programs that promote positive body image and self-esteem.'''
```
Checking length of document / text.


```
# checking the length of textprint('length of text:',len(text))length of text: 688
```
Step 2: Importing important libraries.
--------------------------------------


```
# importing the important librariesimport spacy from spacy.lang.en.stop_words import STOP_WORDSfrom string import punctuation
```
Step 3: Loading English tokenizer, tagger, parser and NER.
----------------------------------------------------------

Let’s understand what are these terms tokenizer, tagger, parser and NER.

**Tokenization** —The process of segmenting a document /paragraph /text into words, sentences, punctuations marks etc is called tokenization.

**Part-of-speech** (POS) **Tagging —** Assigning word types to tokens, like verb or noun.

**Dependency Parsing —**Assigning syntactic dependency labels, describing the relations between individual tokens, like subject or object.

**Named Entity Recognition** (NER) — Labelling named “real-world” objects, like persons, companies or locations.


```
nlp = spacy.load('en_core_web_sm')
```
Step 4: Calling the ‘nlp’ object on a string of text which will return a processed document.
--------------------------------------------------------------------------------------------


```
doc = nlp(text)doc
```
Output:


```
Yoga develops inner awareness. It focuses your attention on your body's abilities at the present moment.It helps develop breath and strength of mind and body. It's not about physical appearance.Yoga studios typically don't have mirrors. This is so people can focus their awareness inward rather than how a pose — or the people around them — looks.Surveys have found that those who practiced yoga were more aware of their bodies than people who didn't practice yoga.They were also more satisfied with and less critical of their bodies. For these reasons, yoga has become an integral part in the treatment of eating disorders and programs that promote positive body image and self-esteem.
```
performing word tokenization here , to check the tokens.


```
tokens = [token.text for token in doc]tokens
```
Output: This is a snapshot of how the output will look like, even the fullstops are tokenized here. Our next steps will be to remove any unwanted punctuations.

![]()Step 5:Adding extra punctuations.
---------------------------------


```
punctuation = punctuation + '\n                 'punctuation
```
Output:


```
'!"#$%&\'()*+,-./:;<=>?@[\\]^_`{|}~\n                 '
```
Step 6: Text Preprocessing and cleaning.
----------------------------------------

Text Preprocessing is a very important step when working with text data.

The code below iterates over ‘doc’, checks for three conditions and counts the occurrences of words in the ‘doc’.


```
word_freq = {}stop_words = list(STOP_WORDS )for word in doc:    if word.text.lower() not in stop_words:        if word.text.lower() not in punctuation:            if word.text.lower() not in word_freq.keys():                word_freq[word.text] = 1            else:                word_freq[word.text] += 1print(word_freq)
```
Output: Count of each word in shown below.


```
{'Yoga': 1, 'develops': 1, 'inner': 1, 'awareness': 2, 'focuses': 1, 'attention': 1, 'body': 3, 'abilities': 1, 'present': 1, 'moment': 1, 'helps': 1, 'develop': 1, 'breath': 1, 'strength': 1, 'mind': 1, 'physical': 1, 'appearance': 1, 'studios': 1, 'typically': 1, 'mirrors': 1, 'people': 3, 'focus': 1, 'inward': 1, 'pose': 1, '—': 2, 'looks': 1, 'Surveys': 1, 'found': 1, 'practiced': 1, 'yoga': 3, 'aware': 1, 'bodies': 2, 'practice': 1, 'satisfied': 1, 'critical': 1, 'reasons': 1, 'integral': 1, 'treatment': 1, 'eating': 1, 'disorders': 1, 'programs': 1, 'promote': 1, 'positive': 1, 'image': 1, 'self': 1, 'esteem': 1}
```
checking the max count of words.


```
print('max count :',max(word_freq.values()))max count : 3
```
Step 7: Normalizing frequency counts.
-------------------------------------

The intend to perform normalization is


```
# normalizing the frequency countsfor word in word_freq.keys():    word_freq[word] = word_freq[word] / max(word_freq.values())#we get the normalized frequency valuesprint(word_freq)
```
Output:


```
{'Yoga': 0.3333333333333333, 'develops': 0.3333333333333333, 'inner': 0.3333333333333333, 'awareness': 0.6666666666666666, 'focuses': 0.3333333333333333, 'attention': 0.3333333333333333, 'body': 1.0, 'abilities': 0.3333333333333333, 'present': 0.3333333333333333, 'moment': 0.3333333333333333, 'helps': 0.3333333333333333, 'develop': 0.3333333333333333, 'breath': 0.3333333333333333, 'strength': 0.3333333333333333, 'mind': 0.3333333333333333, 'physical': 0.3333333333333333, 'appearance': 0.3333333333333333, 'studios': 0.3333333333333333, 'typically': 0.3333333333333333, 'mirrors': 0.3333333333333333, 'people': 1.0, 'focus': 0.3333333333333333, 'inward': 0.3333333333333333, 'pose': 0.3333333333333333, '—': 0.6666666666666666, 'looks': 0.3333333333333333, 'Surveys': 0.3333333333333333, 'found': 0.3333333333333333, 'practiced': 0.3333333333333333, 'yoga': 1.0, 'aware': 0.5, 'bodies': 1.0, 'practice': 1.0, 'satisfied': 1.0, 'critical': 1.0, 'reasons': 1.0, 'integral': 1.0, 'treatment': 1.0, 'eating': 1.0, 'disorders': 1.0, 'programs': 1.0, 'promote': 1.0, 'positive': 1.0, 'image': 1.0, 'self': 1.0, 'esteem': 1.0}
```
Step 8: Sentence Tokenization.
------------------------------

Segregating all the sentences in the ‘doc’ into tokens.


```
sent_tokens = [sent for sent in doc.sents]sent_tokens
```
Output: list of tokenized sentences.


```
[Yoga develops inner awareness., It focuses your attention on your body's abilities at the present moment., It helps develop breath and strength of mind and body., It's not about physical appearance., Yoga studios typically don't have mirrors., This is so people can focus their awareness inward rather than how a pose — or the people around them — looks.,  
  Surveys have found that those who practiced yoga were more aware of their bodies than people who didn't practice yoga., They were also more satisfied with and less critical of their bodies., For these reasons, yoga has become an integral part in the treatment of eating disorders and programs that promote positive body image and self-esteem., ]
```
Step 9: Finding sentence scores.
--------------------------------


```
sent_score = {}for sent in sent_tokens:    for word in sent:        if word.text.lower() in word_freq.keys():            if sent not in sent_score.keys():                sent_score[sent] = word_freq[word.text.lower()]            else:                sent_score[sent] += word_freq[word.text.lower()]print(sent_score)
```
Output:


```
{Yoga develops inner awareness.: 2.333333333333333, It focuses your attention on your body's abilities at the present moment.: 2.6666666666666665, It helps develop breath and strength of mind and body.: 2.6666666666666665, It's not about physical appearance.: 0.6666666666666666, Yoga studios typically don't have mirrors.: 1.9999999999999998, This is so people can focus their awareness inward rather than how a pose — or the people around them — looks.: 5.333333333333334, Surveys have found that those who practiced yoga were more aware of their bodies than people who didn't practice yoga.: 6.166666666666666, They were also more satisfied with and less critical of their bodies.: 3.0, For these reasons, yoga has become an integral part in the treatment of eating disorders and programs that promote positive body image and self-esteem.: 13.0}
```
Step 10: Selecting 30% sentences with maximum scores.
-----------------------------------------------------

We will only be selecting 30% of those sentences with maximum scores.


```
from heapq import nlargestsummary = nlargest(n = 3 , iterable = sent_score , key = sent_score.get)print(summary)  

```
Output:


```
# summary for the original document ['For these reasons, yoga has become an integral part in the treatment of eating disorders and programs that promote positive body image and self-esteem.', "Surveys have found that those who practiced yoga were more aware of their bodies than people who didn't practice yoga.", 'This is so people can focus their awareness inward rather than how a pose — or the people around them — looks.']
```