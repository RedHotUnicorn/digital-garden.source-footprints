---
title: 'GitHub - refuel-ai/autolabel: Label, clean and enrich text datasets with LLMs.'
date: 2023-07-04
src_link: https://www.notion.so/GitHub-refuel-ai-autolabel-Label-clean-and-enrich-text-datasets-with-LLMs-Discord-https-disc-5362d9ab6cee4f208d636958064d6277
src_date: '2023-07-04 19:36:00'
gold_link: https://github.com/refuel-ai/autolabel
gold_link_hash: 8258324ff2d750fab4b3a3ef2815b5cd
tags:
- '#host_github_com'
---

[![](https://raw.githubusercontent.com/refuel-ai/autolabel/main/docs/assets/Autolabel_blk_w_background.png)](https://raw.githubusercontent.com/refuel-ai/autolabel/main/docs/assets/Autolabel_blk_w_background.png)


#### [Discord](https://discord.gg/fweVnRx6CU) |
 [Twitter](https://twitter.com/RefuelAI) |
 [Website](https://www.refuel.ai/) |
 [Benchmark](https://www.refuel.ai/blog-posts/llm-labeling-technical-report)


[![](https://github.com/refuel-ai/autolabel/actions/workflows/black.yaml/badge.svg)](https://github.com/refuel-ai/autolabel/actions/workflows/black.yaml/badge.svg) [![](https://github.com/refuel-ai/autolabel/actions/workflows/test.yaml/badge.svg)](https://github.com/refuel-ai/autolabel/actions/workflows/test.yaml/badge.svg) [![](https://camo.githubusercontent.com/7dbeb159f30ca1164acb6ab6a25913976e7d882e742893a71d2f517c462a8ef4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f636f6d6d69742d61637469766974792f6d2f72656675656c2d61692f6175746f6c6162656c)](https://camo.githubusercontent.com/7dbeb159f30ca1164acb6ab6a25913976e7d882e742893a71d2f517c462a8ef4/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f636f6d6d69742d61637469766974792f6d2f72656675656c2d61692f6175746f6c6162656c) [![](https://camo.githubusercontent.com/6d01c34b4f2e0f3937c92b22685f0017914264505b92cdd4c3afc74ba3cea13d/68747470733a2f2f696d672e736869656c64732e696f2f646973636f72642f31303938373436363933313532393331393031)](https://discord.gg/fweVnRx6CU) [![](https://camo.githubusercontent.com/f5e0d0538a9c2972b5d413e0ace04cecd8efd828d133133933dfffec282a4e1b/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667)](https://colab.research.google.com/drive/1t-9vNLkyoyySAG_0w3eR98biBOXlMO-E?usp=sharing)


⚡ Quick Install
---------------


`pip install refuel-autolabel`


📖 Documentation
---------------


[https://docs.refuel.ai/](https://docs.refuel.ai/)


🏷 What is Autolabel
-------------------


Access to [large, clean and diverse](https://twitter.com/karpathy/status/1528443124577513472?lang=en) labeled datasets is a critical component for any machine learning effort to be successful. State-of-the-art LLMs like GPT-4 are able to [automatically label data](https://arxiv.org/abs/2303.15056) with [high accuracy](https://arxiv.org/abs/2303.16854), and at a fraction of the cost and time compared to manual labeling.


Autolabel is a Python library to label, clean and enrich text datasets with any Large Language Models (LLM) of your choice.


🌟 (New!) Benchmark models on Refuel's Benchmark
-----------------------------------------------


Check out our [technical report](https://refuel.ai/blog-posts/announcing-refuel-llm-2) to learn more about the performance of RefuelLLM-v2 on our benchmark. You can replicate the benchmark yourself by following the steps below



```
cd autolabel/benchmark
curl https://autolabel-benchmarking.s3.us-west-2.amazonaws.com/data.zip -o data.zip
unzip data.zip
python benchmark.py --model $model --base_dir benchmark-results
python results.py --eval_dir benchmark-results
cat results.csv
```

You can benchmark the relevant model by replacing $model with the name of the model needed to be benchmarked. If it is an API hosted model like `gpt-3.5-turbo`, `gpt-4-1106-preview`, `claude-3-opus-20240229`, `gemini-1.5-pro-preview-0409` or some other Autolabel supported model, just write the name of the model. If the model to be benchmarked is a [vLLM supported model](https://docs.vllm.ai/en/latest/models/supported_models.html) then pass the local path or the huggingface path corresponding to the model. This will run the benchmark along with the *same* prompts for all models.


The `results.csv` will contain a row with every model that was benchmarked as a row. Look at `benchmark/results.csv` for an example.


🚀 Getting started
-----------------


Autolabel provides a simple 3-step process for labeling data:


1. Specify the labeling guidelines and LLM model to use in a JSON config.
2. Dry-run to make sure the final prompt looks good.
3. Kick off a labeling run for your dataset!


Let's imagine we are building an ML model to analyze sentiment analysis of movie review. We have a dataset of movie reviews that we'd like to get labeled first. For this case, here's what the example dataset and configs will look like:



```
{
    "task_name": "MovieSentimentReview",
    "task_type": "classification",
    "model": {
        "provider": "openai",
        "name": "gpt-3.5-turbo"
    },
    "dataset": {
        "label_column": "label",
        "delimiter": ","
    },
    "prompt": {
        "task_guidelines": "You are an expert at analyzing the sentiment of movie reviews. Your job is to classify the provided movie review into one of the following labels: {labels}",
        "labels": [
            "positive",
            "negative",
            "neutral"
        ],
        "few_shot_examples": [
            {
                "example": "I got a fairly uninspired stupid film about how human industry is bad for nature.",
                "label": "negative"
            },
            {
                "example": "I loved this movie. I found it very heart warming to see Adam West, Burt Ward, Frank Gorshin, and Julie Newmar together again.",
                "label": "positive"
            },
            {
                "example": "This movie will be played next week at the Chinese theater.",
                "label": "neutral"
            }
        ],
        "example_template": "Input: {example}\nOutput: {label}"
    }
}
```

Initialize the labeling agent and pass it the config:



```
from autolabel import LabelingAgent, AutolabelDataset

agent = LabelingAgent(config='config.json')
```

Preview an example prompt that will be sent to the LLM:



```
ds = AutolabelDataset('dataset.csv', config = config)
agent.plan(ds)
```

This prints:



```
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 100/100 0:00:00 0:00:00
┌──────────────────────────┬─────────┐
│ Total Estimated Cost     │ $0.538  │
│ Number of Examples       │ 200     │
│ Average cost per example │ 0.00269 │
└──────────────────────────┴─────────┘
─────────────────────────────────────────

Prompt Example:
You are an expert at analyzing the sentiment of movie reviews. Your job is to classify the provided movie review into one of the following labels: [positive, negative, neutral]

Some examples with their output answers are provided below:

Example: I got a fairly uninspired stupid film about how human industry is bad for nature.
Output:
negative

Example: I loved this movie. I found it very heart warming to see Adam West, Burt Ward, Frank Gorshin, and Julie Newmar together again.
Output:
positive

Example: This movie will be played next week at the Chinese theater.
Output:
neutral

Now I want you to label the following example:
Input: A rare exception to the rule that great literature makes disappointing films.
Output:

─────────────────────────────────────────────────────────────────────────────────────────


```

Finally, we can run the labeling on a subset or entirety of the dataset:



```
ds = agent.run(ds)
```

The output dataframe contains the label column:



```
ds.df.head()
                                                text  ... MovieSentimentReview_llm_label
0  I was very excited about seeing this film, ant...  ...                       negative
1  Serum is about a crazy doctor that finds a ser...  ...                       negative
4  I loved this movie. I knew it would be chocked...  ...                       positive
...
```

Features
--------


1. Label data for [NLP tasks](https://docs.refuel.ai/guide/tasks/classification_task/) such as classification, question-answering and named entity-recognition, entity matching and more.
2. Use commercial or open source [LLMs](https://docs.refuel.ai/guide/llms/llms/) from providers such as OpenAI, Anthropic, HuggingFace, Google and more.
3. Support for research-proven LLM techniques to boost label quality, such as few-shot learning and chain-of-thought prompting.
4. [Confidence estimation](https://docs.refuel.ai/guide/accuracy/confidence/) and explanations out of the box for every single output label
5. [Caching and state management](https://docs.refuel.ai/guide/reliability/state-management/) to minimize costs and experimentation time


Access to Refuel hosted LLMs
----------------------------


Refuel provides access to hosted open source LLMs for labeling, and for estimating confidence This is helpful, because you can calibrate a confidence threshold for your labeling task, and then route less confident labels to humans, while you still get the benefits of auto-labeling for the confident examples.


In order to use Refuel hosted LLMs, you can [request access here](https://refuel-ai.typeform.com/llm-access).


🛠️ Roadmap
----------


Check out our [public roadmap](https://github.com/orgs/refuel-ai/projects/15) to learn more about ongoing and planned improvements to the Autolabel library.


We are always looking for suggestions and contributions from the community. Join the discussion on [Discord](https://discord.gg/fweVnRx6CU) or open a [Github issue](https://github.com/refuel-ai/autolabel/issues) to report bugs and request features.


🙌 Contributing
--------------


Autolabel is a rapidly developing project. We welcome contributions in all forms - bug reports, pull requests and ideas for improving the library.


1. Join the conversation on [Discord](https://discord.gg/fweVnRx6CU)
2. Open an [issue](https://github.com/refuel-ai/autolabel/issues) on Github for bugs and request features.
3. Grab an open issue, and submit a [pull request](https://github.com/refuel-ai/autolabel/blob/main/CONTRIBUTING.md).