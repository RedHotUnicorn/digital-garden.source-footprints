---
title: Полезные материалы по Data Science и машинному обучению, которые помогут пройти
  сквозь джунгли из терминов / Habr
date: 2023-04-27
src_link: https://www.notion.so/Data-Science-337cab966efb40c7bbfaa6d7143fde5e
src_date: '2023-04-27 11:26:00'
gold_link: https://habr.com/en/companies/selectel/articles/723854/
gold_link_hash: 7bb01eabf8ac536792795caac731c6f0
tags:
- '#host_habr_com'
---

![](https://habrastorage.org/r/w1560/webt/e7/sg/fy/e7sgfyj5vnujmgildz1f5onrnpe.png)  

Привет, Хабр! Меня зовут Ефим, я MLOps-инженер в Selectel. В прошлом был автоматизатором, ML-инженером, дата-аналитиком и дата-инженером — и уже несколько лет падаю в пропасть машинного обучения и Data Science. Это буквально необъятная сфера, в которой почти нет ориентиров. Основная проблема в том, что разделов математики довольно много и все они, на первый взгляд, нужны в том же машинном обучении.  

  

В этой статье делюсь полезными материалами, которые помогут найти и заполнить теоретические и практические проблемы и основательно подойти к своему профессиональному развитию. Добро пожаловать под кат!  

  

**Используйте навигацию, если не хотите читать текст полностью:**  

  

→ [Почему машинное обучение — это сложно](#1)  

→ [Нейронные сети](#2)  

→ [Выстраиваем работу с ML](#3)  

→ [Машинное обучение](#4)  

→ [Основы статистики, все части](#5)  

→ [Анализ данных в R, все части](#6)  

→ [Введение в математический анализ](#7)  

→ [Теория вероятностей — наука о случайности, все части](#8)  

→ [Курсы и гайды на Kaggle](#9)  

→ [Платформа DataCamp](#10)  

→ [Платформа Dataquest](#11)  

→ [Платформа Jovian](#12)  

→ [Канал StatQuest with Josh Starmer](#13)  

→ [Блог Machine Learning Mastery](#14)  

  

Почему машинное обучение — это сложно
-------------------------------------

  

Для начала хотелось бы напомнить, почему одним курсом по машинному обучению и Data Science не обойтись.  

  

Сфер применения машинного обучения много: от рекомендательных движков в музыкальных приложениях, до оценки благонадежности кредитуемого (aka задача кредитного скоринга). Спрос на специалистов, разбирающихся в предметной области и способных грамотно применять методы ML, постоянно растет.  

  

В начале пути кажется, что создать собственный сервис просто: в сети есть открытые высокоуровневые библиотеки вроде PyTorch, TensorFlow, ONNX и других инструментов. Тем не менее, в силу специфики области возникает огромное количество вопросов. И даже понимание «основ» машинного обучения не избавляет от подводных камней — а их может быть много. Постараюсь это показать.  

  

**Представьте ситуацию. Вы — начинающий специалист.** И вам нужно некое портфолио, чтобы продемонстрировать потенциальному работодателю свои навыки и знания. Кроме того, их нужно где-то приобрести и поддерживать в актуальном состоянии.  

  

Вы решили, что будете разрабатывать свой ML-сервис для распознавания лиц. Допустим, он будет построен на базе сверточных нейронных сетей и вы уже разобрались с формальной постановкой задачи (подозреваю, что там некоторым образом всплывут термины вроде [Face Recognition](https://paperswithcode.com/task/face-recognition) и [Face Identification](https://paperswithcode.com/task/face-identification)). Предположим, что вы даже уже определились с выбором нужных инструментов — например Python, PyTorch и PyTorch Lighting. Какие вопросы могут возникнуть?  

  

* Есть ли примеры кода для выбранных задач, или нужно будет имплементировать архитектуру сети с нуля?
* Если примеры кода есть, достаточно ли будет [Transfer Learning](https://paperswithcode.com/task/transfer-learning) или придется прикручивать [Fine Tuning](https://paperswithcode.com/methods/category/fine-tuning) для моделей?
* В случае Fine Tuning какой набор данных нужен для создания проекта?
* Если своих данных нет, откуда их можно взять?

  

И это лишь часть вопросов, с которыми можно столкнуться на этапе создания, казалось бы, простого сервиса. Могут появиться задачи, связанные вовсе не с данными, а с работой модели.  

  

* Как разработать кастомную функцию потерь или функцию активации?
* Можно ли как-то осознанно выбрать [гиперпараметры](https://wiki.loginom.ru/articles/hyperparameters.html) модели?
* На что вообще эти гиперпараметры влияют, есть ли рамки для каждого из них?
* Что делать, если возникла ошибка с размерностью входного слоя?
* Как имплементировать [SOTA-архитектуру](https://www.e2enetworks.com/blog/what-is-sota-in-artificial-intelligence)?
* Как интерпретировать полученные результаты?

  

До сих пор это лишь часть проблем, с которыми можно столкнуться из-за незнания математического аппарата. Например, есть параметр momentum. Это один из гиперпараметров, применяемых в обучении нейронной сети с использованием одной из вариаций стохастического градиентного спуска [Adam](https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/) (**Ada**ptive **M**oment estimation). Чтобы просто понять, зачем этот параметр там нужен, нужно как минимум знать, что такое градиент. Это предполагает знание элементов математического анализа и концепции взвешенной суммы.  

  

#### Машинное обучение — это о математике

  

Давайте разберем один из сценариев в прошлом разделе: начинающему ML-инженеру нужно самостоятельно имплементировать SOTA-архитектуру на готовом фреймворке.  

  

В рамках задачи разработчику нужно будет самостоятельно расписать все слои SOTA и понять, как они между собой связаны — а это уже, как минимум, линейная алгебра и, возможно, тензорный анализ. На этом пункте многие скажут: «Очевидно, что ML-инженер должен знать эти дисциплины» — и будут правы.  

  

Теория без практики мертва, но практика без теории слепа. Неважно, как вы изучаете: сверху вниз или снизу вверх, от общего к частному или от частного к общему — важно найти для себя некую точку баланса. Вот, как взаимосвязи в Data Science вижу я:  

  

![](https://habrastorage.org/r/w1560/webt/lu/hm/at/luhmattwhbm9a0mk4xwguirq3ho.png)  

Теперь посмотрим, какие же ресурсы и курсы можно пошерстить, чтобы погрузиться в этот dependency hell.  

  

Введение в Data Science и машинное обучение
-------------------------------------------

  

![](https://habrastorage.org/r/w1560/webt/yo/6d/wz/yo6dwzj3gotp13p3uwnue5r2ygq.png)  

Хороший курс для тех, кто только-только начинает вливаться в Data Science и машинное обучение. Простой, без академического снобизма и тонны громоздких терминов.  

  

Лектор Анатолий Карпов рассказывает о наиболее популярных и надежных инструментах, которые применяют в различных компаниях при решении коммерческих задач. При этом в курсе есть достаточный минимум погружения в технические детали. Для меня этот курс был полезен тем, что помог структурировать уже имеющиеся знания и посмотреть на знакомые технологии под другим углом.  

  

**Источник →** курс доступен по [ссылке](https://stepik.org/course/4852/syllabus).  

  

[![](https://habrastorage.org/r/w1560/webt/5z/ks/ck/5zksckdm42qellywosligbrxeoy.png)](https://selectel.ru/services/cloud/davm/?utm_source=habr.com&utm_medium=referral&utm_campaign=cloud_article_dscience_210323_banner_046_ord)  

  

Нейронные сети
--------------

  

![](https://habrastorage.org/r/w1560/webt/l7/vi/tf/l7vitfpkmzoylnioqq8h3m99ej4.png)  

Этот курс дает возможность разобраться в устройстве оптимизаторов и даже написать свою версию. В курсе хорошо преподнесены вводные по линейной алгебре и имплементация метода обратного распространения ошибки на NumPy.  

  

Курс особенно полезен для тех, у кого есть «база», новичкам его рекомендовать не могу.  

  

**Источник →** изучайте нейронные сети по [ссылке](https://stepik.org/course/401/syllabus).  

  

Выстраиваем работу с ML
-----------------------

  

Недавно мы с коллегами запустили курс «Выстраиваем работу с ML». В нем собрали полезные материалы для компаний, которые внедряют машинное обучение в рабочие процессы. Подробно рассмотрели концепцию MLOps — дисциплину, направленную на унификацию процессов разработки и развертывания ML-систем. Также рассмотрели отдельные инструменты для работы с ML-моделями и подробно осветили понятие платформы обработки данных.  

  

![](https://habrastorage.org/r/w1560/webt/jj/av/us/jjavusracgvzb7yb9pq_foucmzs.png)  

**Источник →** узнайте больше о ML по [ссылке](https://selectel.ru/blog/courses/how-to-work-with-ml-systems/).  

  

Машинное обучение
-----------------

  

![](https://habrastorage.org/r/w1560/webt/p1/rn/cu/p1rncujifnye8mm0f5qx0webs9g.png)  

Это исключительно вводный курс, который скорее заинтересует, чем сделает из вас специалиста. Бережно и аккуратно рассказывает о базовых сущностях, которые лежат в основе математического аппарата машинного обучения. Поэтому курс особенно полезен для специалистов смежных направлений — например, техническим писателям.  

  

**Источник →** курс доступен по [ссылке](https://stepik.org/course/8057/info).  

  

Основы статистики, все части
----------------------------

  

![](https://habrastorage.org/r/w1560/webt/_h/or/qd/_horqdeotvuf_czw6vukgoepiv4.png)  

Один из лучших курсов для «осторожного» погружения в работу статистических критериев, теорию формирования выборок и прочего.  

  

Лектор Анатолий Карпов объясняет, из чего состоит критерий Стьюдента, в чем смысл центральной предельной теоремы, зачем нужно A/B-тестирование и другие вещи. Я бы сказал, этот курс полезен всем, потому что учит трезво оценивать реальность, осмыслять происходящие в ней события и случайные процессы.  

  

**Источник →** первая часть доступна по [ссылке](https://stepik.org/course/76/info).  

  

Во второй части курса «Основы статистики» уже больше критериев и деталей.  

  

**Источник →** вторая часть доступна по [ссылке](https://stepik.org/course/524/info).  

  

Третья часть курса еще сильнее погружает в вопросы линейной регрессии. Обсуждаются мультиколлинеарность, гетероскедастичность и другие проблемы, с которыми можно столкнуться в процессе построения регрессионных и классификационных моделей.  

  

**Источник →** третья часть доступна по [ссылке](https://stepik.org/course/2152/info).  

  

Анализ данных в R, все части
----------------------------

  

![](https://habrastorage.org/r/w1560/webt/nn/_7/q9/nn_7q9zms8oalkn9bqlv-_h2kwi.png)  

Говоря о курсах по основам статистики, имеет смысл упомянуть и курс по анализу данных в R. Поскольку все примеры, иллюстрирующие идеи и концепции из статистики, демонстрируются именно на этом языке.  

  

Первая часть курса не распыляется и покрывает только часть тем — знакомство с синтаксисом, работу с датасетами и их визуализацию. Но этого вполне достаточно, чтобы влиться в язык и погрузиться в более сложные темы вроде RSpark.  

  

**Источник →** первая часть доступна по [ссылке](https://stepik.org/course/129/info).  

  

Вторая часть логически развивает материал первой. В ней более пристально расписаны способы, как шерудить данные (преимущественно табличные), отрисовывать их и строить отчеты с помощью R Markdown.  

  

Трудно сказать, насколько вам пригодится материал из этой части. Но если вы решили, что тематика языка R вам близка, то с помощью курса можете закрепить полученные знания.  

  

**Источник →** вторая часть доступна по [ссылке](https://stepik.org/course/724/info).  

  

Введение в математический анализ
--------------------------------

  

![](https://habrastorage.org/r/w1560/webt/yw/qd/xe/ywqdxesdxhvdcjt9smjcevu8etg.png)  

Не проходил курс полностью, но есть одна вещь, из-за которой готов его рекомендовать — это задачи. Почти в самом начале наткнулся на пример, который вогнал меня в ступор.  

  

![](https://habrastorage.org/r/w1560/webt/kp/ec/ep/kpecepvpi5ts5obqmfjlb5mpan0.png)  

Решил задачу только со 117 попытки. 🥲 Не делайте так: лучше пропускать подобные задачи и идти по курсу дальше. Это позволит изучить его до конца и лучше понять, где используются пределы в машинном обучении.  

  

**Источник →** проходите курс по [ссылке](https://stepik.org/course/95/info).  

  

Теория вероятностей — наука о случайности, все части
----------------------------------------------------

  

![](https://habrastorage.org/r/w1560/webt/nr/6x/gf/nr6xgfpp0fcbbcqducuz_pblfk4.png)  

*Этот курс оставил дыру в моем сердце…* Я выполнил верно практически все задания, но стоило дать слабину на единственном разделе — и прощай, пройденный на 100% курс. Так или иначе, первая часть очень достойная и подойдет даже тем, кто уже знаком с теорией вероятностей.  

  

**Источник →** первая часть доступна по [ссылке](https://stepik.org/course/2911/info).  

  

Вторая часть гораздо интересней и без шуток. Она погружает читателя в борелевскую сигма-алгебру, процессы Бернулли и Пуассона, многомерные и условные непрерывные распределения. Надо ли изучать эти темы на старте? Точно нет. Стоит ли отложить этот курс и вернуться к нему позже? Да, безусловно!  

  

Это по-настоящему полезный курс: машинное обучение буквально «сквозит» условными распределениями и понимание этой математической конструкции может сильно помочь в освоении сложного материала.  

  

**Источник →** вторая часть доступна по [ссылке](https://stepik.org/course/3209/info).  

  

Курсы и гайды на Kaggle
-----------------------

  

![](https://habrastorage.org/r/w1560/webt/wi/oh/ff/wiohffvcmjdw5adia1yc_gglckq.png)  

С пониманием таких вещей как permutation importance, partial dependence, SHapley Additive exPlanations (SHAP) и другим мне помог именно курс на Kaggle — [Machine Learning](https://www.kaggle.com/learn/machine-learning-explainability) [Explainability](https://www.kaggle.com/learn/machine-learning-explainability).  

  

Все курсы Kaggle встроены в интерфейс платформы, сопровождаются листингами с кодом и подробными комментариями. После теоретического блока можно поэкспериментировать с кодом, что достаточно удобно.  

  

**Источник →** все курсы и гайды доступны по [ссылке](https://www.kaggle.com/learn).  

  

Платформа DataCamp
------------------

  

![](https://habrastorage.org/r/w1560/webt/5u/lg/go/5ulggozyk4s1cmi9c_5ghhkh7ek.png)  

Платформа напоминает что-то вроде судоку или сканворда. Практическая польза от этой платформы в том, что можно набить руку на написании однотипных блоков кода. Так, можно запомнить, например, как считать абсолютную разницу двух столбцов в библиотеке Pandas или критерий Стьюдента в SciPy. Можно ли всё это сделать без подобной платформы? Конечно. Но если у вас есть желание обернуть это все в околоигровую форму, можно воспользоваться подобной платформой.  

  

**Источник →** в «судоку» можно поиграть по [ссылке](https://www.datacamp.com/).  

  

Платформа Dataquest
-------------------

  

![](https://habrastorage.org/r/w1560/webt/wp/hh/gl/wphhglmvnzxfy36s0fak_5m8skk.png)  

Это примерно такой же сканворд, как и DataCamp. Но значительная часть курсов на Dataquest платная. Можно, конечно, идти по программе курса и просто гуглить материалы самостоятельно, но тогда вы лишите себя главного плюса этой платформы — визуализации результатов и прокаченных навыков. Другой вопрос, а нужно ли оно вам?  

  

**Источник →** курсы доступны по [ссылке](https://app.dataquest.io/).  

  

Платформа Jovian
----------------

  

![](https://habrastorage.org/r/w1560/webt/od/or/cs/odorcsfsaknscpf_mvbqiutuyke.png)  

Уже довольно сложно найти что-то новое или оригинальное в экспоненциально возрастающем количестве курсов. Если вы хотите найти гайд по конкретной теме, попробуйте это сделать на Jovian. Это хорошая платформа-обучалка с акцентом в сторону Jupyter Notebook. Мне особенно приглянулись курсы по [Deep Learning](https://jovian.com/learn/deep-learning-with-pytorch-zero-to-gans), [Machine Learning](https://jovian.com/learn/machine-learning-with-python-zero-to-gbms) и [Natural Language Processing](https://jovian.com/learn/nautral-language-processing-zero-to-nlp). Большая часть материалов на Jovian бесплатна.  

  

**Источник →** подключайтесь по [ссылке](https://jovian.com/).  

  

Канал StatQuest with Josh Starmer
---------------------------------

  

![](https://habrastorage.org/r/w1560/webt/jp/cv/3f/jpcv3fpgvtg-utxtftwij6snpiu.png)  

В своё время я получил массу удовольствия от просмотра видео на канале StatQuest with Josh Starmer. Автор классно объясняет математические модели и методы — например, как работают случайные леса, логистическая регрессия, статистические тесты и другое. Особенно рекомендую [видео](https://www.youtube.com/watch?v=i4iUvjsGCMc) о том, что там BAM!!!  

  

**Источник →** на канал можно попасть по этой [ссылке](https://www.youtube.com/@statquest).  

  


> **Возможно, эти тексты тоже вас заинтересуют:**  
> 
>   
> 
> → [Бот из машины. Как инженеру сократить время на диагностику дисков](https://habr.com/ru/company/selectel/blog/722082)  
> 
> → [Знакомство с частотными фильтрами. Часть 1: как спроектировать и немного схитрить](https://habr.com/ru/company/selectel/blog/721558)  
> 
> → [5 полезных и просто занимательных проектов на Raspberry Pi начала весны 2023 года](https://habr.com/ru/company/selectel/blog/722398)

  

Блог Machine Learning Mastery
-----------------------------

  

![](https://habrastorage.org/r/w1560/webt/4x/9w/fh/4x9wfhpnmadrim9hjnpjncta-a8.png)  

В этом блоге можно найти массу примеров кода с разными фреймворками и полезные статьи. Довольно интересный [материал](https://machinelearningmastery.com/loss-functions-in-pytorch-models/), на который я недавно наткнулся, посвящен Loss-функциям в PyTorch. Рекомендую курс тем, кто хочет узнать больше деталей из привычной разработки нейронных сетей.   

  

**Источник →** читайте блог по [ссылке](https://machinelearningmastery.com/blog).  

  

Заключение
----------

  

Как вы поняли, образовательных ресурсов много. И чтобы стать специалистом, нужно основательно подойти к их изучению, а также следить за новыми технологиями в мире машинного обучения и Data Science. Кстати, с последним мы помогаем в нашем [Telegram-сообществе «MLечный путь»](https://t.me/%2BhmAmPogLcIhhN2Ni). Там мы публикуем еженедельные дайджесты по DataOps и MLOps, обсуждаем проблемы и лучшие практики организации production ML-сервисов, а также обмениваемся опытом. Присоединяйтесь к более 700 специалистам, развивающим ML- и Data-направления в российских и зарубежных компаниях.  

  


> А какие источники для погружения в Data Science и ML знаете вы? Поделитесь своими вариантами в комментариях.