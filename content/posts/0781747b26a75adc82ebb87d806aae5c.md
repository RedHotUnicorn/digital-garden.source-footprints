---
title: 'OpenAssistant: Вышла бесплатная открытая альтернатива ChatGPT / Habr'
date: 2023-04-26
src_link: https://www.notion.so/OpenAssistant-ChatGPT-afa6fc27b26f482cada69d1f0dd0e1de
src_date: '2023-04-26 10:02:00'
gold_link: https://habr.com/en/articles/729158/
gold_link_hash: 0781747b26a75adc82ebb87d806aae5c
tags:
- '#host_habr_com'
---

![](https://habrastorage.org/getpro/habr/upload_files/87d/ec4/d9f/87dec4d9f0d43d80c550fbfa2b04a45c.png)Участники открытого сообщества [LAION-AI](https://laion.ai/) выпустили в открытый доступ первые обученные [модели](https://huggingface.co/Black-Engineer) [OA\_SFT\_Llama\_30B](https://huggingface.co/Black-Engineer/oasst-llama30b-ggml-q4) и [OA\_SFT\_Llama\_13B](https://huggingface.co/Black-Engineer/llama-13b-pretrained-sft-do2-ggml-q4). и запустили ИИ-чатбот [OpenAssistant](https://open-assistant.io/chat/) на их основе. На текущий момент доступны модели в 13 и 30 млрд параметров, дообученные на мультиязычных датасетах, собранных сообществом. В основе моделей лежит уже успевшая стать популярной [LLaMA](https://ai.facebook.com/blog/large-language-model-llama-meta-ai/). 

[OpenAssistant](https://open-assistant.io/chat/) - это диалоговый помощник на базе ИИ, который понимает задачи, может взаимодействовать со сторонними системами (подобно плагинам в ChatGPT) и динамически извлекать информацию из них. OpenAssistant позиционируется как открытая альтернатива ChatGPT.

*"Мы хотим, чтобы OpenAssistant стал единой, объединяющей платформой, которую все другие системы используют для взаимодействия с людьми."* *- декларируют своё видение члены сообщества LAION.*

Вы можете попробовать поговорить с OpenAssistant уже сейчаст [тут](https://open-assistant.io/ru/chat).

Еще вы можете принять участие в формировании датасета на своём языке [тут](https://open-assistant.io/ru/dashboard).

Технические детали
------------------

Модели обучали на мощностях, выделенных [Redmond AI](https://redmond.ai/) при поддержке [Weights & Biases](https://wandb.ai/site). Инференс моделей обеспечивается благодаря [Hugging Face](https://huggingface.co/) и [Stability AI](https://stability.ai/). В основе дообученных моделей лежат концепции [InstructGPT](https://arxiv.org/abs/2203.02155), [RLHF](https://huggingface.co/blog/rlhf) (Reinforcement Learning from Human Feedback) и модель вознаграждения ([reward-model](https://huggingface.co/OpenAssistant/reward-model-deberta-v3-large-v2)) на базе [deBERTa](https://huggingface.co/OpenAssistant/reward-model-deberta-v3-large-v2). Контекст модели в 30 млрд увеличен в 2 раза, до 1024 токена.

![](https://habrastorage.org/getpro/habr/upload_files/abb/a96/a8b/abba96a8bcc2df307056530705b42174.png)Сообщество приложило усилия для [формирования](https://open-assistant.io/ru/dashboard) полноценного датасета, который составляется и проверяется большой группой людей на разных языках и разного уровня подготовки. Для целей сбора датасета, реализован алгоритм, при котором одна группа участников сообщества формируют вопросы и ответы, а другая группа занимается валидацией в несколько уровней.

![](https://habrastorage.org/getpro/habr/upload_files/38a/5b2/7aa/38a5b27aab48a1914a9ac4c3f02e1423.png)Датасет является мультиязычным, основные доли занимают Английский (59%) и Испанский (42%). Доля Русского языка на уровне 8%. Мы можем повлиять на это, приняв участие в разметке датасета.  


![](https://habrastorage.org/getpro/habr/upload_files/ac7/219/f9b/ac7219f9b8e0261baed852ffaba48e2c.png)Стоит учесть тот факт, что при подготовке датасета [не использовались](https://github.com/LAION-AI/Open-Assistant/issues/471#issuecomment-1374392299) ответы от других языковых моделей, таких как ChatGPT, чтобы исключить попадание синтетических данных. Весь код Open Assistant лицензирован под Apache 2.0. Это означает, что он доступен для широкого круга целей, включая коммерческое использование.

![](https://habrastorage.org/getpro/habr/upload_files/b4c/c8f/c8a/b4cc8fc8a120c4405b53bdc547b55e17.png)**OpenAssistent это:**

* Персонализированный кастомизируемый диалоговый ИИ ассистент
* Система извлечения информации из внешних ресурсов и знаний
* Система взаимодействия с другими системами через API интерфейсы
* Система генерации и автодополнения кода для разработчиков

**OpenAssistent** объединяет все знания в одном месте:

* Использует современные технологии глубокого обучения
* Способен запускаться на пользовательском оборудовании
* Дообучен на обратной связи от живых людей
* Открыт и доступен для всех

### Инференс

Вы можете запустить **OpenAssistent** у себя на компьютере локально на CPU. Для этого вам нужно:

1. [Скачать](https://github.com/ggerganov/llama.cpp/releases/download/master-f2d1c47/llama-master-f2d1c47-bin-win-avx-x64.zip) и распаковать файлы из архива.

2. [Скачать](https://huggingface.co/Black-Engineer/llama-13b-pretrained-sft-do2-ggml-q4/resolve/main/qunt4_0.bin) модель и поместить в ту же директорию.

3. Открыть терминал (cmd.exe) и запустить с помощью команды:

main.exe -m D:\LLaMA\_cpp\qunt4\_0.bin -n -1 --ctx\_size 2048 --batch\_size 16 --keep 512 --repeat\_penalty 1.0 -t 32 --temp 0.4 --top\_k 30 --top\_p 0.18 --interactive-first -ins --color

где D:\LLaMA\_cpp\qunt4\_0.bin - это путь до скачанной модели.

![](https://habrastorage.org/getpro/habr/upload_files/22a/2d6/501/22a2d650190d309e7d7d8679f35b12e5.png "так выглядит инференс модели в 13 млрд.")

так выглядит инференс модели в 13 млрд.

### Тесты

Тесты проводились на модели в 30 млрд:

![](https://habrastorage.org/getpro/habr/upload_files/d00/4a5/f2f/d004a5f2f4e2ae34187621919a39a9fc.png)#### На русском языке:

![](https://habrastorage.org/getpro/habr/upload_files/dff/98d/8e0/dff98d8e0668091684242eb14663ed0f.png "OpenAssistant")

OpenAssistant

![](https://habrastorage.org/getpro/habr/upload_files/409/516/717/409516717dc7e573e58b7486a2dec172.png "ChatGPT")

ChatGPT

![](https://habrastorage.org/getpro/habr/upload_files/901/390/b6b/901390b6bb9bd0df37393f2f9bd86152.png "O")

O

Справилась! Или был пример в датасете?

![](https://habrastorage.org/getpro/habr/upload_files/185/9a2/ed4/1859a2ed4091204424e2ddaeb7c10c9c.png)![](https://habrastorage.org/getpro/habr/upload_files/aa7/a8a/5e3/aa7a8a5e3510d7ae72dc8fc2cfbe2402.png)Вроде как да, но вроде и нет?

![](https://habrastorage.org/getpro/habr/upload_files/8b7/007/c39/8b7007c398ae00a6a53013017191b50f.png)![](https://habrastorage.org/getpro/habr/upload_files/658/91e/c85/65891ec8571f4b2db29134ec8cf4a5d5.png)Ну такое.

![](https://habrastorage.org/getpro/habr/upload_files/9b2/ea7/2fe/9b2ea72fe87b805b7c6081839dd791e2.png)#### На английском языке:

![](https://habrastorage.org/getpro/habr/upload_files/695/e1e/605/695e1e6053c9ee28a582a9981640d1aa.png)Ошибка!. Верный ответ: Option D. This is an alternating number of subtraction series. First, 1 is subtracted, then 2 is added.

![](https://habrastorage.org/getpro/habr/upload_files/d3a/928/98d/d3a92898d8638ffb9aca6a89953361b5.png)![](https://habrastorage.org/getpro/habr/upload_files/029/742/f9b/029742f9b8ea7e63b244904cd6a15b8b.png)Правильный ответ: D. Book. Rest are all parts of a book.

![](https://habrastorage.org/getpro/habr/upload_files/ee6/05f/85f/ee605f85f5b03442c97d95bf0fabbba6.png)![](https://habrastorage.org/getpro/habr/upload_files/d47/923/4d4/d479234d47223cce886c52ac5ce0ffb7.png)Логично!

![](https://habrastorage.org/getpro/habr/upload_files/693/bc8/6ea/693bc86ea38c7822c1c5d1524d96ca84.png)Ну вроде адекватный ответ.

![](https://habrastorage.org/getpro/habr/upload_files/e76/8e5/142/e768e5142bd756c393eef1e747bb65b4.png)![](https://habrastorage.org/getpro/habr/upload_files/481/b68/4c7/481b684c77a92958cd629b576de7785d.png)По генерации кода по запросу всё выглядит лучше.

![](https://habrastorage.org/getpro/habr/upload_files/86f/d31/1e8/86fd311e889e82c2a77662586f646bbc.png)#### Вердикт.

В целом круто, что сообщество развивает подобные проекты. Я уверен, у этого проекта есть огромный потенциал и в будущем мы ещё о нём услышим! Силу сообщества нельзя недооценивать!

На данный момент модель пока **сырая**. До ChatGPT даже версии GPT-3.5 ей пока далеко. Еще один немаловажный нюанс - это лицензия основной модели LLaMA. C ней вопрос пока далеко не однозначный, т.к. по сути она была слита и авторы это публично никак не комментируют.

Подписывайтесь на мой канал [titanida](https://titanida.com/) (про ИИ, языковые модели, новости и тенденции) и телеграм каналы: [awesome chatgpt](https://t.me/awesome_chatgpt) (статьи, мысли и ресерчи на тему ИИ и языковые модели) и [hardupgrade](https://t.me/hardupgrade) (про организацию, структурирование и управление информацией, второй мозг).